{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd762f39-807a-4fa9-9db7-c479d0039e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7742b-025e-461a-991a-3d075875c5da",
   "metadata": {},
   "source": [
    "### Locally disabling gradient computation\n",
    "\n",
    "The context managers `torch.no_grad()`, `torch.enable_grad()`, and `torch.set_grad_enabled()` are helpful for locally disabling and enabling gradient computation.\n",
    "\n",
    "These context managers are thread local, so they won't work if you send work to another thread using the `threading` module, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd41631-7239-4b58-a272-a0722715bce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab20c5e-b387-4b01-aebe-acf50031d603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_train = False\n",
    "with torch.set_grad_enabled(is_train):\n",
    "    y = x * 2\n",
    "\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b29530-859c-4b82-b4a7-96ec9b5bdaa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb5d184e-fd42-43e9-864d-a893eff74f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857d96b-2942-4ee0-a8d7-0dfc3d800988",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Context managers\n",
    "\n",
    "1. [torch.no_grad](#torch.no_grad)\n",
    "2. [torch.enable_grad](#torch.enable_grad)\n",
    "3. [torch.set_grad_enabled](#torch.set_grad_enabled)\n",
    "4. [torch.is_grad_enabled](#torch.is_grad_enabled)\n",
    "5. [torch.inference_mode](#torch.inference_mode)\n",
    "6. [torch.is_inference_mode_enabled](#torch.is_inference_mode_enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee344c-7420-4f6e-a941-89f1ae90c2d1",
   "metadata": {},
   "source": [
    "<a id=\"torch.no_grad\"></a>\n",
    "### 1. torch.no_grad\n",
    "\n",
    "Context-manager that disables gradient calculation.\n",
    "\n",
    "Disabling gradient calculation is useful for **inference**, when you are sure that you will not call `Tensor.backward()`. It will reduce memory consumption for computations that would otherwise have `requires_grad=True`.\n",
    "\n",
    "In this mode, the result of every computation will have `require_grad=False`, even when the inputs have `require_grad=True`. There is an exception! All factory functions that create new Tensor and take a requires_grad kwarg, will NOT be affected by this mode.\n",
    "\n",
    "This context manager is thread local; it will not affect computation in other threads.\n",
    "\n",
    "Also functions as decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a97928-0ea9-44db-be39-94c9028184ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f475902d-2a3c-48e6-bb67-9d1c649d14e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cad5ac5-bae7-4a63-870c-32562b014654",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def tripler(x):\n",
    "    return x * 3\n",
    "z = tripler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "368d91bd-e2e9-45d3-80b8-9f2dec260f45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# factory function exception\n",
    "with torch.no_grad():\n",
    "    a = torch.nn.Parameter(torch.randn(10))\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34545762-4215-4c6c-adc5-0708b47b5ce2",
   "metadata": {},
   "source": [
    "<a id=\"torch.enable_grad\"></a>\n",
    "\n",
    "### 2. torch.enable_grad\n",
    "\n",
    "`torch.enable_grad(orig_func=None)`\n",
    "\n",
    "Context-manager that enables gradient calculation.\n",
    "\n",
    "Enables gradient calculation, if it has been disabled via [`no_grad()`](#torch.no_grad)  or [`set_grad_enabled`](#torch.set_grad_enabled).\n",
    "\n",
    "This context manager is thread local; it will not affect computation in other threads.\n",
    "\n",
    "Also functions as a decotator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075d92c9-788d-4c9d-a097-bfd9a6fcd359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    with torch.enable_grad():\n",
    "        y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b358fd9-3db4-401e-bc4e-c24a6c924cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e2145b-a390-46d2-96e8-2db7a7296941",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.enable_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "with torch.no_grad():\n",
    "    z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ac98a75-7c16-4839-bda6-cdbd4d3364c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.enable_grad\n",
    "def tripler(x):\n",
    "    return x * 3\n",
    "with torch.no_grad():\n",
    "    z = tripler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff776b-04e9-4dea-b7aa-92ea7af6482b",
   "metadata": {},
   "source": [
    "<a id=\"torch.set_grad_enabled\"></a>\n",
    "\n",
    "### 3. torch.set_grad_enabled\n",
    "\n",
    "`torch.set_grad_enabled(mode)`\n",
    "\n",
    "Context-manager that sets gradient calcuation on or off.\n",
    "\n",
    "`set_grad_enabled` will enable or disable grads based on its arguments `mode`. It can be used as a context-manager or as a fucntion.\n",
    "\n",
    "This context manager is thread local; it will not affect computation in other threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba15f762-e885-48cb-83a3-7d333e2b6001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "is_train = False\n",
    "with torch.set_grad_enabled(is_train):\n",
    "    y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69c2fc57-ad4e-4fbd-af95-9d16a33f13ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used as a function\n",
    "_ = torch.set_grad_enabled(True)\n",
    "y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa8761df-b996-4c74-afe0-668b70852759",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = torch.set_grad_enabled(False)\n",
    "y = x * 2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7884c-fca9-4408-a0db-cc9a5b15ce47",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"torch.sis_grad_enabled\"></a>\n",
    "\n",
    "### 4. torch.is_grad_enabled\n",
    "\n",
    "`torch.is_grad_enabled()`\n",
    "\n",
    "Returns True if grad mode is currently enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98ad7234-a323-4e63-a13a-2f240db3a329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_grad_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a190190f-4fdd-45f0-b7f2-aa0b27897740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = torch.set_grad_enabled(True)\n",
    "torch.is_grad_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439c5f6-cd67-433e-8ba1-a11858c5c8ce",
   "metadata": {},
   "source": [
    "<a id=\"torch.inference_mode\"></a>\n",
    "\n",
    "### 5. torch.inference_mode\n",
    "\n",
    "`torch.inference_mode(mode=True)`\n",
    "\n",
    "Context manager that enables or disables inference mode.\n",
    "\n",
    "InferenceMode is a new context manager analogous to `no_grad` to be used when you are certain your operations will have no interactions with autograd (e.g., model_training). Code ran under this mode gets better performance by disabling view tracking and version counter bumps. Note that unlike some other mechanism that locally enable or diable grad, entering inference_mode also disables to `forward-mode AD`.\n",
    "\n",
    "This context manager is thread local; it will not affect computation in other threads.\n",
    "\n",
    "Also functions as a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c766f2c6-8285-41ec-aa74-43830f3defa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1, 2, 3, requires_grad=True)\n",
    "with torch.inference_mode():\n",
    "    y = x * x\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca43b4e8-4ce1-4861-ac0e-221ad89a3cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Inference tensors do not track version counter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inference tensors do not track version counter."
     ]
    }
   ],
   "source": [
    "y._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "931e097b-5125-4bdd-bad8-189ed6bfec27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def func(x):\n",
    "    return x * x\n",
    "out = func(x)\n",
    "out.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2e8d826-d8c5-4075-9172-2dd87b760644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.inference_mode\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "out = doubler(x)\n",
    "out.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b316bbd-7a51-48b3-b380-144dc151d6c0",
   "metadata": {},
   "source": [
    "<a id=\"torch.is_inference_mode_enabled\"></a>\n",
    "\n",
    "### 6. torch.is_inference_mode_enabled\n",
    "\n",
    "`torch.is_inference_mode_enabled()`\n",
    "\n",
    "Returns True if inference mode is currently enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf761859-1b16-478f-a41e-ddf3f2a57847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_inference_mode_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efec53f0-6034-40a4-bf07-b7e6b646cfe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    print(torch.is_inference_mode_enabled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912052bc-011d-4842-8a42-b9d551241624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
